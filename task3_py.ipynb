{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLZaHtcAnGfLY+37awVqiu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kanimozhi-Perumal/Kanimozhi-Perumal/blob/main/task3_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDkUbhkPMBxi"
      },
      "outputs": [],
      "source": [
        "To implement a simple text generation algorithm using Markov chains, we'll create a statistical model that predicts the next character or word based on the current sequence of characters or words in the input text. Markov chains are probabilistic models that assume the probability of each possible state depends only on the previous state. Hereâ€™s how you can proceed:\n",
        "\n",
        "Steps to Implement Markov Chain Text Generation\n",
        "Step 1: Choose a Corpus\n",
        "A corpus is a large body of text from which the Markov chain will learn and generate new text. For simplicity, let's use a small example text.\n",
        "\n",
        "plaintext\n",
        "\n",
        "Example Text:\n",
        "\"Dark Background with Neon Lights. PRODIGY INFOTECH. Text Generation with Markov Chains.\"\n",
        "Step 2: Preprocess the Text\n",
        "Clean the text by removing unnecessary characters and converting it into tokens (characters or words). In this example, let's tokenize based on words.\n",
        "\n",
        "python\n",
        "\n",
        "# Example text\n",
        "text = \"Dark Background with Neon Lights. PRODIGY INFOTECH. Text Generation with Markov Chains.\"\n",
        "\n",
        "# Tokenize based on words (split by spaces)\n",
        "tokens = text.split()\n",
        "\n",
        "# Check tokens\n",
        "print(tokens)\n",
        "# Output: ['Dark', 'Background', 'with', 'Neon', 'Lights.', 'PRODIGY', 'INFOTECH.', 'Text', 'Generation', 'with', 'Markov', 'Chains.']\n",
        "Step 3: Build the Markov Chain Model\n",
        "Create a function that builds a Markov chain model from the tokens. This function will count the occurrences of each token following a given sequence of tokens (order) and store these probabilities.\n",
        "\n",
        "python\n",
        "\n",
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "def build_markov_chain(tokens, order=1):\n",
        "    # Initialize a dictionary to hold the Markov chain\n",
        "    markov_chain = defaultdict(list)\n",
        "\n",
        "    # Iterate through the tokens to build the chain\n",
        "    for i in range(len(tokens) - order):\n",
        "        current_state = tuple(tokens[i:i + order])  # Current state (tuple of tokens)\n",
        "        next_state = tokens[i + order]              # Next state (single token)\n",
        "        markov_chain[current_state].append(next_state)\n",
        "\n",
        "    return markov_chain\n",
        "\n",
        "# Build Markov chain model with order 1 (using words)\n",
        "markov_model = build_markov_chain(tokens, order=1)\n",
        "\n",
        "# Example output of the Markov model\n",
        "# defaultdict(<class 'list'>, {('Dark',): ['Background'], ('Background',): ['with'], ('with',): ['Neon'], ...})\n",
        "Step 4: Generate Text\n",
        "Create a function to generate new text based on the Markov chain model. Start with a random seed (initial state) and use the probabilities stored in the model to generate subsequent tokens.\n",
        "\n",
        "python\n",
        "\n",
        "def generate_text(markov_chain, max_length=50):\n",
        "    # Start with a random initial state\n",
        "    current_state = random.choice(list(markov_chain.keys()))\n",
        "    generated_text = list(current_state)\n",
        "\n",
        "    # Generate text\n",
        "    while len(generated_text) < max_length:\n",
        "        next_state_options = markov_chain[current_state]\n",
        "        next_state = random.choice(next_state_options)\n",
        "        generated_text.append(next_state)\n",
        "        current_state = tuple(generated_text[-len(current_state):])\n",
        "\n",
        "    return ' '.join(generated_text)\n",
        "\n",
        "# Generate text using the Markov model\n",
        "generated_text = generate_text(markov_model)\n",
        "print(generated_text)\n",
        "Example Output\n",
        "Running the generate_text function might produce outputs like:\n",
        "\n",
        "arduino\n",
        "\n",
        "\"Neon Lights. PRODIGY INFOTECH. Text Generation with Neon Lights.\"\n",
        "Summary\n",
        "This simple implementation demonstrates how to build and use a Markov chain model for text generation based on a given corpus. You can adjust the order parameter to change the length of the sequence used to predict the next token (word). For character-level text generation, modify the tokenization and model building steps accordingly.\n",
        "\n",
        "Markov chains provide a basic but effective approach to generating text that exhibits statistical patterns similar to the training data. For more sophisticated text generation tasks, consider exploring deep learning models like LSTM or transformer-based models like GPT-2/GPT-3, which can capture more complex dependencies in the text data.\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}